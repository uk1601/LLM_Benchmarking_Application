{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T06:35:54.871015Z",
     "start_time": "2024-09-23T06:35:54.337638Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Login using e.g. `huggingface-cli login` to access this dataset\n",
    "ds = load_dataset(\"gaia-benchmark/GAIA\", \"2023_all\")\n",
    "validation = ds[\"validation\"]\n",
    "print(validation)\n",
    "type(validation[1][\"Annotator Metadata\"])"
   ],
   "id": "255a157b37f4901",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['task_id', 'Question', 'Level', 'Final answer', 'file_name', 'file_path', 'Annotator Metadata'],\n",
      "    num_rows: 165\n",
      "})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T06:38:37.552670Z",
     "start_time": "2024-09-23T06:38:27.056641Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import csv\n",
    "import psycopg2\n",
    "import json\n",
    "from psycopg2.extras import Json\n",
    "\n",
    "# Database connection parameters\n",
    "db_params = {\n",
    " \n",
    "}\n",
    "from datasets import load_dataset\n",
    "import psycopg2\n",
    "import json\n",
    "from psycopg2.extras import Json\n",
    "\n",
    "\n",
    "# Function to insert data into the Tasks table\n",
    "def insert_task(cursor, task_id, question, level, expected_answer, file_name, file_path, annotations):\n",
    "    sql = \"\"\"\n",
    "    INSERT INTO Tasks (TaskId, Question, ExpectedAnswer, Level, FileName, FilePath, Annotations)\n",
    "    VALUES (%s, %s, %s, %s, %s, %s, %s)\n",
    "    ON CONFLICT (TaskId) DO UPDATE SET\n",
    "    Question = EXCLUDED.Question,\n",
    "    ExpectedAnswer = EXCLUDED.ExpectedAnswer,\n",
    "    Level = EXCLUDED.Level,\n",
    "    FileName = EXCLUDED.FileName,\n",
    "    FilePath = EXCLUDED.FilePath,\n",
    "    Annotations = EXCLUDED.Annotations\n",
    "    \"\"\"\n",
    "    cursor.execute(sql, (task_id, question, expected_answer, level, file_name, file_path, Json(annotations)))\n",
    "\n",
    "# Main function to process the dataset and insert data\n",
    "def process_dataset():\n",
    "    # Load the dataset\n",
    "    ds = load_dataset(\"gaia-benchmark/GAIA\", \"2023_all\")\n",
    "    validation_set = ds[\"validation\"]\n",
    "\n",
    "    conn = psycopg2.connect(**db_params)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    try:\n",
    "        for row in validation_set:\n",
    "            task_id = row['task_id']\n",
    "            question = row['Question']\n",
    "            level = row['Level']\n",
    "            expected_answer = row['Final answer']\n",
    "            file_name = row['file_name'] if row['file_name'] else None\n",
    "            file_path = row['file_path'] if row['file_path'] else None\n",
    "            annotations = row['Annotator Metadata']\n",
    "\n",
    "            insert_task(cursor, task_id, question, level, expected_answer, file_name, file_path, annotations)\n",
    "\n",
    "        conn.commit()\n",
    "        print(f\"Data inserted successfully! {validation_set.num_rows} rows processed.\")\n",
    "\n",
    "    except (Exception, psycopg2.Error) as error:\n",
    "        print(\"Error while inserting data:\", error)\n",
    "        conn.rollback()\n",
    "\n",
    "    finally:\n",
    "        if conn:\n",
    "            cursor.close()\n",
    "            conn.close()\n",
    "\n",
    "# Run the script\n",
    "if __name__ == \"__main__\":\n",
    "    process_dataset()"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inserted successfully! 165 rows processed.\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T07:04:16.309095Z",
     "start_time": "2024-09-23T07:04:16.268547Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datetime import datetime\n",
    "from sqlalchemy import Boolean, DateTime\n",
    "# data_layer.a\n",
    "\n",
    "from sqlalchemy import create_engine, Column, Integer, String, JSON\n",
    "# from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import sessionmaker, declarative_base\n",
    "\n",
    "Base = declarative_base()\n",
    "from sqlalchemy import create_engine, Column, Integer, String, JSON, Boolean, DateTime\n",
    "from sqlalchemy.orm import sessionmaker, declarative_base\n",
    "from datetime import datetime\n",
    "\n",
    "Base = declarative_base()\n",
    "\n",
    "class Task(Base):\n",
    "    __tablename__ = 'tasks'\n",
    "\n",
    "    taskid = Column(String, primary_key=True, name=\"taskid\")  # lowercase column names\n",
    "    question = Column(String, nullable=False, name=\"question\")\n",
    "    expectedanswer = Column(String, name=\"expectedanswer\")\n",
    "    level = Column(Integer, name=\"level\")\n",
    "    filename = Column(String, name=\"filename\")\n",
    "    filepath = Column(String, name=\"filepath\")\n",
    "    annotations = Column(JSON, name=\"annotations\")\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"<Task(taskid='{self.taskid}', question='{self.question[:30]}...', level={self.level})>\"\n",
    "\n",
    "class LLM(Base):\n",
    "    __tablename__ = 'llms'\n",
    "\n",
    "    llmid = Column(Integer, primary_key=True, name=\"llmid\")\n",
    "    llmname = Column(String, nullable=False, name=\"llmname\")\n",
    "    version = Column(String, name=\"version\")\n",
    "    parameters = Column(String, name=\"parameters\")\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"<LLM(llmid={self.llmid}, llmname='{self.llmname}', version='{self.version}')>\"\n",
    "\n",
    "class LLMResponse(Base):\n",
    "    __tablename__ = 'llmresponses'\n",
    "\n",
    "    responseid = Column(Integer, primary_key=True, name=\"responseid\")\n",
    "    taskid = Column(String, name=\"taskid\")\n",
    "    llmid = Column(Integer, name=\"llmid\")\n",
    "    responsetext = Column(String, nullable=False, name=\"responsetext\")\n",
    "    isannotated = Column(Boolean, default=False, name=\"isannotated\")\n",
    "    resultcategory = Column(String, name=\"resultcategory\")\n",
    "    timestamp = Column(DateTime, default=datetime.utcnow, name=\"timestamp\")\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"<LLMResponse(responseid={self.responseid}, taskid='{self.taskid}', llmid={self.llmid})>\"\n",
    "\n",
    "# Database connection\n",
    "DATABASE_URL = \"\"\n",
    "engine = create_engine(DATABASE_URL)\n",
    "SessionMaker = sessionmaker(bind=engine)\n"
   ],
   "id": "fb8cbf052d5918fc",
   "outputs": [],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T07:05:42.992088Z",
     "start_time": "2024-09-23T07:05:42.985300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# data_access.py\n",
    "\n",
    "from sqlalchemy.orm import Session\n",
    "# from data_layer import Task, LLM, LLMResponse\n",
    "\n",
    "class DataAccess:\n",
    "    def __init__(self, session: Session):\n",
    "        self.session = session\n",
    "\n",
    "    def get_all_tasks(self):\n",
    "        return self.session.query(Task).all()\n",
    "\n",
    "    def get_task_by_id(self, task_id: str):\n",
    "        return self.session.query(Task).filter(Task.taskid == task_id).first()\n",
    "\n",
    "    def get_tasks_by_level(self, level: int):\n",
    "        return self.session.query(Task).filter(Task.level == level).all()\n",
    "\n",
    "    def get_all_llms(self):\n",
    "        return self.session.query(LLM).all()\n",
    "\n",
    "    def get_llm_by_id(self, llm_id: int):\n",
    "        return self.session.query(LLM).filter(LLM.llmid == llm_id).first()\n",
    "\n",
    "    def get_responses_for_task(self, task_id: str):\n",
    "        return self.session.query(LLMResponse).filter(LLMResponse.taskid == task_id).all()\n",
    "\n",
    "    def get_responses_for_llm(self, llm_id: int):\n",
    "        return self.session.query(LLMResponse).filter(LLMResponse.llmid == llm_id).all()"
   ],
   "id": "48df3151b359a656",
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T07:05:39.812799Z",
     "start_time": "2024-09-23T07:05:39.338324Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# main.py\n",
    "\n",
    "# from sqlalchemy.orm import Session\n",
    "# from data_layer import engine, Session as SessionMaker\n",
    "# from data_access import DataAccess\n",
    "\n",
    "def main():\n",
    "    session = SessionMaker()\n",
    "    data_access = DataAccess(session)\n",
    "\n",
    "    try:\n",
    "        # Get all tasks\n",
    "        all_tasks = data_access.get_all_tasks()\n",
    "        print(f\"Total tasks: {len(all_tasks)}\")\n",
    "\n",
    "        # Get a specific task\n",
    "        task = data_access.get_task_by_id(\"c61d22de-5f6c-4958-a7f6-5e9707bd3466\")\n",
    "        if task:\n",
    "            print(f\"Task question: {task.question}\")\n",
    "            print(f\"Task expected answer: {task.expectedanswer}\")\n",
    "            print(f\"Task annotations: {task.annotations}\")\n",
    "\n",
    "        # Get tasks by level\n",
    "        level_2_tasks = data_access.get_tasks_by_level(2)\n",
    "        print(f\"Level 2 tasks: {len(level_2_tasks)}\")\n",
    "\n",
    "        # Get all LLMs\n",
    "        all_llms = data_access.get_all_llms()\n",
    "        print(f\"Total LLMs: {len(all_llms)}\")\n",
    "\n",
    "        # Get responses for a specific task\n",
    "        task_responses = data_access.get_responses_for_task(\"c61d22de-5f6c-4958-a7f6-5e9707bd3466\")\n",
    "        print(f\"Responses for task: {len(task_responses)}\")\n",
    "\n",
    "    finally:\n",
    "        session.close_all()\n",
    "        \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "54bf88d9150a7b62",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tasks: 165\n",
      "Task question: A paper about AI regulation that was originally submitted to arXiv.org in June 2022 shows a figure with three axes, where each axis has a label word at both ends. Which of these words is used to describe a type of society in a Physics and Society article submitted to arXiv.org on August 11, 2016?\n",
      "Task expected answer: egalitarian\n",
      "Task annotations: {'Steps': '1. Go to arxiv.org and navigate to the Advanced Search page.\\n2. Enter \"AI regulation\" in the search box and select \"All fields\" from the dropdown.\\n3. Enter 2022-06-01 and 2022-07-01 into the date inputs, select \"Submission date (original)\", and submit the search.\\n4. Go through the search results to find the article that has a figure with three axes and labels on each end of the axes, titled \"Fairness in Agreement With European Values: An Interdisciplinary Perspective on AI Regulation\".\\n5. Note the six words used as labels: deontological, egalitarian, localized, standardized, utilitarian, and consequential.\\n6. Go back to arxiv.org\\n7. Find \"Physics and Society\" and go to the page for the \"Physics and Society\" category.\\n8. Note that the tag for this category is \"physics.soc-ph\".\\n9. Go to the Advanced Search page.\\n10. Enter \"physics.soc-ph\" in the search box and select \"All fields\" from the dropdown.\\n11. Enter 2016-08-11 and 2016-08-12 into the date inputs, select \"Submission date (original)\", and submit the search.\\n12. Search for instances of the six words in the results to find the paper titled \"Phase transition from egalitarian to hierarchical societies driven by competition between cognitive and social constraints\", indicating that \"egalitarian\" is the correct answer.', 'Tools': '1. Web browser\\n2. Image recognition tools (to identify and parse a figure with three axes)', 'Number of steps': '12', 'Number of tools': '2', 'How long did this take?': '8 minutes'}\n",
      "Level 2 tasks: 86\n",
      "Total LLMs: 0\n",
      "Responses for task: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_z/ms9rqjt90dq1s5797l_x0ry40000gn/T/ipykernel_40487/1970016400.py:36: SADeprecationWarning: The Session.close_all() method is deprecated and will be removed in a future release.  Please refer to session.close_all_sessions(). (deprecated since: 1.3)\n",
      "  session.close_all()\n"
     ]
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "24da582e79c1f308"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
